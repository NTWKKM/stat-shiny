import streamlit as st
import pandas as pd
import numpy as np
import math

def _is_numeric_column(col_series: pd.Series, total_rows: int) -> tuple:
    """
    Determine if a column should be treated as numeric.
    Returns: (is_numeric, strict_numeric_series, relaxed_numeric_series, strict_nan_mask, strict_nan_count)
    """
    original_vals = col_series.astype(str).str.strip()
    
    # Strict check
    numeric_strict = pd.to_numeric(col_series, errors='coerce')
    is_strict_nan = numeric_strict.isna() & (original_vals != '') & \
                    (~original_vals.str.lower().isin(['nan', 'none', '']))
    strict_nan_count = is_strict_nan.sum()
    
    # Relaxed check
    clean_vals = original_vals.str.replace(r'[<>,%]', '', regex=True)
    numeric_relaxed = pd.to_numeric(clean_vals, errors='coerce')
    
    is_relaxed_numeric = (~numeric_relaxed.isna()) & (original_vals != '') & \
                         (~original_vals.str.lower().isin(['nan', 'none', '']))
    relaxed_numeric_count = is_relaxed_numeric.sum()
    
    non_empty_mask = (original_vals != '') & (~original_vals.str.lower().isin(['nan', 'none']))
    total_data_count = non_empty_mask.sum()
    has_inequality = original_vals.str.contains(r'[<>]', regex=True).any()
    
    # Decision logic
    is_numeric_col = False
    if total_data_count > 0:
        ratio = relaxed_numeric_count / total_data_count
        if ratio > 0.6:
            is_numeric_col = True
        elif has_inequality and ratio > 0.4:
            is_numeric_col = True
    else:
        if strict_nan_count < (total_rows * 0.9):
            is_numeric_col = True
    
    return is_numeric_col, numeric_strict, numeric_relaxed, is_strict_nan, strict_nan_count

def check_data_quality(df, container):
    """
    Data Quality Checker (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß): 
    1. Numeric Column -> ‡∏´‡∏≤ Text ‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏•‡∏≠‡∏° (‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î <, >) ‡πÅ‡∏•‡∏∞‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö Strict
    2. Text Column    -> ‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏•‡∏á‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≠‡∏¢‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
    """
    warnings = [] 
    total_rows = len(df)
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ (‡∏Å‡∏£‡∏ì‡∏µ‡∏•‡∏ö‡∏à‡∏ô‡∏´‡∏°‡∏î) ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°
    if total_rows == 0:
        return

    for col in df.columns:
        col_issues = []
        
        # Use helper function
        is_numeric_col, numeric_strict, _, is_strict_nan, strict_nan_count = _is_numeric_column(df[col], total_rows)

        # CASE 1: Numeric
        if is_numeric_col:
            if strict_nan_count > 0:
                error_rows = df.index[is_strict_nan].tolist()
                bad_values = df.loc[is_strict_nan, col].unique()
                row_str = ",".join(map(str, error_rows[:3])) + ("..." if len(error_rows) > 3 else "")
                val_str = ",".join(map(str, bad_values[:3])) + ("..." if len(bad_values) > 3 else "")
                col_issues.append(f"Found {strict_nan_count} non-standard values at rows `{row_str}` (Values: `{val_str}`).")

        # CASE 2: Categorical
        else:
            original_vals = df[col].astype(str).str.strip()
            is_numeric_in_text = (~numeric_strict.isna()) & (original_vals != '')
            numeric_in_text_count = is_numeric_in_text.sum()
            if numeric_in_text_count > 0:
                error_rows = df.index[is_numeric_in_text].tolist()
                bad_values = df.loc[is_numeric_in_text, col].unique()
                row_str = ",".join(map(str, error_rows[:3])) + ("..." if len(error_rows) > 3 else "")
                col_issues.append(f"Found {numeric_in_text_count} numeric values inside categorical column at rows `{row_str}`.")

            unique_ratio = df[col].nunique() / total_rows
            if unique_ratio < 0.8: 
                val_counts = df[col].value_counts()
                rare_threshold = 5 
                rare_vals = val_counts[val_counts < rare_threshold].index.tolist()
                if len(rare_vals) > 0:
                     val_str = ", ".join(map(str, rare_vals[:3])) + ("..." if len(rare_vals) > 3 else "")
                     col_issues.append(f"Found rare categories (<{rare_threshold} times): `{val_str}`.")

        if col_issues:
            full_msg = " ".join(col_issues)
            warnings.append(f"**Column '{col}':** {full_msg}")

    if warnings:
        container.warning("Data Quality Issues (Current Page)\n\n" + "\n\n".join([f"- {w}" for w in warnings]), icon="üßê")

def get_clean_data(df, custom_na_list=None):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà 'Clean' ‡πÅ‡∏•‡πâ‡∏ß (Logic ‡πÄ‡∏î‡∏¥‡∏°)
    """
    df_clean = df.copy()
    total_rows = len(df_clean)

    for col in df_clean.columns:
        if custom_na_list:
             df_clean[col] = df_clean[col].replace(custom_na_list, np.nan)

        if df_clean[col].dtype == 'object':
             df_clean[col] = df_clean[col].astype(str).str.strip()

        # Use helper function
        is_numeric_col, _, numeric_relaxed, _, _ = _is_numeric_column(df_clean[col], total_rows)

        if is_numeric_col:
             df_clean[col] = numeric_relaxed
        
    return df_clean

def render(df):
    st.subheader("Raw Data Table")
    
    # --- Config Section ---
    col_info, col_btn = st.columns([4, 1.5], vertical_alignment="center")
    with col_info:
        st.info("You can view and edit your raw data below.", icon="üí°")

    with col_btn:
        with st.popover("‚öôÔ∏è Config Missing Values", use_container_width=True):
            st.markdown("**Define Custom Missing Values**")
            missing_input = st.text_input("Values separated by comma", value="", placeholder="e.g. -99, 999")
    
    warning_container = st.empty()
    custom_na_list = [x.strip() for x in missing_input.split(',') if x.strip() != '']
    st.session_state['custom_na_list'] = custom_na_list
    
    st.write("") 

    # --- ‚ö° PAGINATION LOGIC ---
    batch_size = 600
    total_rows = len(df)
    total_pages = math.ceil(total_rows / batch_size) if total_rows > 0 else 1

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á container ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤
    if total_pages > 1:
        c1, c2, _ = st.columns([1, 2, 8])
        with c1:
            page = st.number_input("Page", min_value=1, max_value=total_pages, value=1, step=1)
        with c2:
            st.write("") # Spacer
            st.markdown(f"<div style='padding-top: 10px;'>of {total_pages} ({total_rows} rows)</div>", unsafe_allow_html=True)
    else:
        page = 1
        st.caption(f"Showing all {total_rows} rows")

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Index ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏ö‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    start_idx = (page - 1) * batch_size
    end_idx = min(start_idx + batch_size, total_rows)

    # ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á (Slice)
    # ‡πÉ‡∏ä‡πâ .copy() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô SettingWithCopyWarning
    df_slice = df.iloc[start_idx:end_idx].copy()
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å format (‡πÄ‡∏ä‡πà‡∏ô 001, >100)
    df_display_slice = df_slice.astype(str).replace('nan', '')

    # --- EDITOR ---
    # ‡πÄ‡∏£‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏Ñ‡πà Slice ‡πÅ‡∏ï‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠ User ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï df ‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡πà
    edited_slice = st.data_editor(
        df_display_slice, 
        num_rows="dynamic", # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡πÑ‡∏î‡πâ (‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ)
        use_container_width=True, 
        height=450, 
        key=f'editor_raw_page_{page}' # Key ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏≤‡∏°‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠ refresh editor
    )

    # --- UPDATE LOGIC ---
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Slice ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡∏ä‡πâ‡∏≤‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞ ‡πÅ‡∏ï‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö slice 600 ‡πÅ‡∏ñ‡∏ß ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å
    if not df_display_slice.equals(edited_slice):
        # 1. ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á DataFrame ‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡πà (df)
        # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ index ‡∏Ç‡∏≠‡∏á slice ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ô df ‡∏ï‡∏±‡∏ß‡πÅ‡∏°‡πà
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Data Type ‡∏ï‡∏≠‡∏ô update ‡∏Å‡∏•‡∏±‡∏ö
        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÅ‡∏Å‡πâ‡∏à‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô object (text)
        
        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô index ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
        if len(edited_slice) != len(df_slice):
             st.warning("Adding/Deleting rows in pagination mode handles complexity. Please reset data if indices mismatch.")
             # ‡∏Å‡∏£‡∏ì‡∏µ Simple Update:
             # ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡πÉ‡∏ô Pagination ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏°‡∏≤‡∏Å ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ User ‡∏£‡∏∞‡∏ß‡∏±‡∏á
             # ‡πÅ‡∏ï‡πà‡∏ô‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Edit ‡∏Ñ‡πà‡∏≤ (Cell Edit) ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
        
        # Update ‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö
        try:
             # ‡πÉ‡∏ä‡πâ loop update ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
             # ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ update ‡∏Ç‡∏≠‡∏á pandas (‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á index)
             
             # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Original Type ‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô Object ‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô
             # ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Raw Data ‡πÅ‡∏ö‡∏ö Text
             
             # Filter to only update indices that exist in the parent DataFrame
             valid_indices = edited_slice.index.intersection(df.index)
             if len(valid_indices) > 0:
                 df.loc[valid_indices, edited_slice.columns] = edited_slice.loc[valid_indices]
             
             # Force rerun ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
             # st.rerun() # ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö ‡∏õ‡∏¥‡∏î‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô
        except (KeyError, IndexError, ValueError) as e:
             st.error(f"Error updating data: {e}")

    # --- CHECK QUALITY (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ) ---
    # ‡∏™‡πà‡∏á edited_slice ‡πÑ‡∏õ‡πÄ‡∏ä‡πá‡∏Ñ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ User ‡πÄ‡∏´‡πá‡∏ô Warning ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ
    check_data_quality(edited_slice, warning_container)

    # Return ‡∏ï‡∏±‡∏ß df ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÅ‡∏•‡πâ‡∏ß
    return df
