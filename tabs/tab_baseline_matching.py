import streamlit as st
import pandas as pd
import numpy as np
import table_one  # Import from root
import psm_lib  # Import from root
import plotly.express as px
from logger import get_logger

logger = get_logger(__name__)

# üü¢ NEW: Helper function to select between original and matched datasets
def _get_dataset_for_table1(df: pd.DataFrame) -> tuple[pd.DataFrame, str]:
    """
    Choose which dataset to use for Table 1 display and provide a descriptive label.
    """
    has_matched = (
        st.session_state.get("is_matched", False)
        and st.session_state.get("df_matched") is not None
    )

    if has_matched:
        col1, _ = st.columns([2, 1])
        with col1:
            options = ["üìä Original Data", "‚úÖ Matched Data (from PSM)"]
            data_source = st.radio(
                "üìÑ Select Dataset:",
                options,
                index=0,  # default Original for Table 1
                horizontal=True,
                key="table1_data_source",
            )

        if data_source == options[1]:  # Matched Data
            selected_df = st.session_state.df_matched.copy()
            label = f"‚úÖ Matched Data ({len(selected_df)} rows)"
        else:
            selected_df = df.copy()
            label = f"üìä Original Data ({len(df)} rows)"
    else:
        selected_df = df.copy()
        label = f"üìä Original Data ({len(df)} rows)"

    return selected_df, label


def render(df, var_meta):
    """
    Render the "Table 1 & Matching" interactive Streamlit interface.
    """
    st.subheader("üìã Table 1 & Matching")
    
    # üü¢ NEW: Create four subtabs
    sub_tab1, sub_tab2, sub_tab3, sub_tab4 = st.tabs([
        "üìä Baseline Characteristics (Table 1)",
        "‚öñÔ∏è Propensity Score Matching",
        "‚úÖ Matched Data View",
        "‚ÑπÔ∏è Reference & Interpretation"
    ])
    
    # ==========================================
    # SUBTAB 1: BASELINE CHARACTERISTICS (Table 1)
    # ==========================================
    with sub_tab1:
        st.markdown("##### Baseline Characteristics (Table 1)")
        # üßπ Removed detailed description (Moved to Tab 4)
        
        # üü¢ Display matched data status and selector
        if st.session_state.get("is_matched", False):
            st.info("‚úÖ **Matched Dataset Available** - You can select it below for analysis")
        
        # üü¢ Select dataset (original or matched)
        t1_df, t1_label = _get_dataset_for_table1(df)
        st.write(f"**Using:** {t1_label}")
        st.write(f"**Rows:** {len(t1_df)} | **Columns:** {len(t1_df.columns)}")
        
        all_cols = t1_df.columns.tolist()
        grp_idx = 0
        for i, c in enumerate(all_cols):
            if 'group' in c.lower() or 'treat' in c.lower(): 
                grp_idx = i
                break
        
        c1, c2 = st.columns([1, 2])
        with c1:
            col_group = st.selectbox("Group By (Column):", ["None", *all_cols], index=grp_idx+1, key='t1_group')
            
            # üü¢ Added OR Display Option
            or_style_display = st.radio(
                "Choose OR Style:",
                ["All Levels (Every Level vs Ref)", "Simple (Single Line/Risk vs Ref)"],
                index=0,
                key="or_style_radio",
                help="See Reference tab for details."
            )
            # Map display string to internal code
            or_style_code = 'all_levels' if "All Levels" in or_style_display else 'simple'
            
        with c2:
            def_vars = [c for c in all_cols if c != col_group]
            selected_vars = st.multiselect("Include Variables:", all_cols, default=def_vars, key='t1_vars')
            
        run_col, dl_col = st.columns([1, 1])
        
        if 'html_output_t1' not in st.session_state:
            st.session_state.html_output_t1 = None

        if run_col.button("üìä Generate Table 1", type="primary", key='btn_t1'):
            with st.spinner("Generating..."):
                try:
                    grp = None if col_group == "None" else col_group
                    # Calling the generate_table function in table_one.py with or_style
                    # üü¢ UPDATED: Use t1_df (selected dataset) instead of df
                    html_t1 = table_one.generate_table(t1_df, selected_vars, grp, var_meta, or_style=or_style_code)
                    st.session_state.html_output_t1 = html_t1 
                    st.components.v1.html(html_t1, height=600, scrolling=True)
                except Exception as e:
                    st.error(f"Error: {e}")
                    logger.exception("Table 1 generation failed")
                    st.session_state.html_output_t1 = None 
                    
        with dl_col:
            if st.session_state.html_output_t1:
                st.download_button("üì• Download HTML", st.session_state.html_output_t1, "table1.html", "text/html", key='dl_btn_t1')
            else:
                st.button("üì• Download HTML", disabled=True, key='ph_t1')
    
    # ==========================================
    # SUBTAB 2: PROPENSITY SCORE MATCHING
    # ==========================================
    with sub_tab2:
        st.markdown("##### ‚öñÔ∏è Propensity Score Matching (PSM)")
        # üßπ Removed detailed description (Moved to Tab 4)

        all_cols = df.columns.tolist()
        if not all_cols:
            st.error("Dataset has no columns to analyze.")
            return
            
        # ==========================================
        # SECTION 1: VARIABLE CONFIGURATION WITH PRESETS
        # ==========================================
        st.subheader("Step 1Ô∏è‚É£: Configure Variables")
        
        col_preset, col_manual = st.columns([1, 2], gap="large")
        
        with col_preset:
            st.markdown("**Quick Presets:**")
            preset_choice = st.radio(
                "Start with template:",
                ["üîß Custom (Manual)", "üë• Demographics", "üè• Full Medical"],
                index=0,
                label_visibility="collapsed"
            )
            
            st.caption("""
            **Presets include:**
            - üë• Demographics: Age, Sex, BMI
            - üè• Full Medical: Age, Sex, BMI, Comorbidities, Lab values
            - üîß Custom: You choose all variables
            """)
        
        with col_manual:
            st.markdown("**Manual Selection:**")
            
            # Auto-detect Treatment
            treat_idx = 0
            for i, c in enumerate(all_cols):
                if df[c].nunique() == 2 and ('group' in c.lower() or 'treat' in c.lower()):
                    treat_idx = i
                    break
                    
            treat_col = st.selectbox(
                "üíä Treatment Variable (Binary)",
                all_cols,
                index=treat_idx,
                key='psm_treat',
                help="Must have exactly 2 unique values"
            )
            
            outcome_col = st.selectbox(
                "üéØ Outcome Variable (Optional)",
                ["‚äò None / Skip", *all_cols],
                index=0,
                key='psm_outcome',
                help="For comparison after matching"
            )
            
            # Smart covariate defaults based on preset
            # Use membership test instead of string comparison
            excluded_cols = [treat_col]
            if outcome_col in all_cols:
                excluded_cols.append(outcome_col)
            cov_candidates = [c for c in all_cols if c not in excluded_cols]
            
            if preset_choice == "üë• Demographics":
                default_covs = [c for c in cov_candidates if any(x in c.lower() for x in ['age', 'sex', 'bmi'])]
            elif preset_choice == "üè• Full Medical":
                default_covs = [c for c in cov_candidates if any(x in c.lower() for x in ['age', 'sex', 'bmi', 'comorb', 'hyper', 'diab', 'lab'])]
            else:
                default_covs = []
            
            cov_cols = st.multiselect(
                "üìä Confounding Variables",
                cov_candidates,
                default=default_covs,
                key='psm_cov',
                help="Select all baseline variables that might affect treatment assignment"
            )
        
        # ==========================================
        # CONFIGURATION SUMMARY
        # ==========================================
        config_valid = len(cov_cols) > 0
        summary_items = [
            f"üíä **Treatment:** `{treat_col}`",
            f"üéØ **Outcome:** `{outcome_col if outcome_col != '‚äò None / Skip' else 'Skip'}`",
            f"üìä **Confounders:** {len(cov_cols)} selected"
        ]
        
        if not config_valid:
            summary_items.append("‚ùå **Error:** Please select at least one covariate")
        
        st.info("**‚úÖ Configuration Summary:**\n" + "\n".join(summary_items))
        
        # ==========================================
        # SECTION 2: ADVANCED SETTINGS (IMPROVED CALIPER)
        # ==========================================
        with st.expander("‚öôÔ∏è Advanced Settings", expanded=False):
            st.markdown("**Caliper Width (Matching Tolerance)**")
            
            col_cal, col_info = st.columns([2, 1])
            
            with col_cal:
                cal_presets = {
                    "üîì Very Loose (1.0√óSD) - Most matches, weaker balance": 1.0,
                    "üìä Loose (0.5√óSD) - Balanced approach": 0.5,
                    "‚öñÔ∏è Standard (0.25√óSD) - RECOMMENDED ‚Üê START HERE": 0.25,
                    "üîí Strict (0.1√óSD) - Fewer matches, excellent balance": 0.1,
                }
                
                cal_label = st.radio(
                    "Select matching strictness:",
                    list(cal_presets.keys()),
                    index=2,
                    label_visibility="collapsed"
                )
                
                caliper = cal_presets[cal_label]
            
            with col_info:
                st.markdown("**üìå About Caliper:**")
                st.caption("Caliper = max distance to match treated with control. Wider = more matches, less balance.")
        
        # ==========================================
        # SECTION 3: RUN MATCHING
        # ==========================================
        st.subheader("Step 2Ô∏è‚É£: Run Matching")
        
        col_run, col_status = st.columns([2, 1])
        
        run_button = col_run.button(
            "üöÄ Run Propensity Score Matching",
            type="primary",
            disabled=not config_valid,
            use_container_width=True,
            key='btn_psm'
        )
        
        with col_status:
            if config_valid:
                st.success("‚úÖ Ready to run")
            else:
                st.error("‚ö†Ô∏è Select covariates")
        
        # ==========================================
        # SECTION 4: EXECUTION & RESULTS
        # ==========================================
        if run_button:
            if not cov_cols:
                st.error("Please select at least one covariate.")
            else:
                try:
                    # --- Data Preparation ---
                    df_analysis = df.copy()
                    unique_treat = df_analysis[treat_col].dropna().unique()
                    
                    if len(unique_treat) == 0:
                        st.error(f"‚ö†Ô∏è Variable '{treat_col}' contains only missing values.")
                    elif len(unique_treat) != 2:
                        st.warning(f"‚ö†Ô∏è Variable '{treat_col}' must have exactly 2 unique values (Found: {len(unique_treat)}).")
                    else:
                        # Handle categorical treatment
                        is_numeric_binary = set(unique_treat).issubset({0, 1}) or set(unique_treat).issubset({0.0, 1.0})
                        target_val = None
                        final_treat_col = treat_col
                        
                        if not is_numeric_binary:
                            val_counts = df_analysis[treat_col].value_counts()
                            minor_val = val_counts.index[-1]
                            major_val = val_counts.index[0]
                            
                            st.warning(f"""
                            ‚ö†Ô∏è **Treatment variable is categorical:**
                            - **{major_val}:** {val_counts[major_val]} patients ({val_counts[major_val]/len(df_analysis)*100:.1f}%)
                            - **{minor_val}:** {val_counts[minor_val]} patients ({val_counts[minor_val]/len(df_analysis)*100:.1f}%)
                            
                            Using **{minor_val}** as treatment (usually the minority group).
                            """)
                            
                            target_val = minor_val
                            final_treat_col = f"{treat_col}_encoded"
                            df_analysis[final_treat_col] = np.where(df_analysis[treat_col] == target_val, 1, 0)

                        # Initialize cat_covs early to avoid fragile locals() check
                        cat_covs = []

                        # Handle categorical covariates
                        if cov_cols:
                            cat_covs = [c for c in cov_cols if pd.api.types.is_string_dtype(df_analysis[c]) or 
                                       pd.api.types.is_categorical_dtype(df_analysis[c]) or 
                                       pd.api.types.is_object_dtype(df_analysis[c])]
                            if cat_covs:
                                df_analysis = pd.get_dummies(df_analysis, columns=cat_covs, drop_first=True)
                            # Build final covariate list: numeric covs unchanged + new dummy cols from categorical encoding
                            new_cols = [c for c in df_analysis.columns if c not in df.columns and c != final_treat_col]
                            final_cov_cols = [c for c in cov_cols if c not in cat_covs] + new_cols
                        else:
                            final_cov_cols = []
                        
                        # --- Calculate Propensity Scores ---
                        with st.spinner("‚è≥ Calculating propensity scores..."):
                            df_ps, _model = psm_lib.calculate_ps(df_analysis, final_treat_col, final_cov_cols)
                        
                        # --- Perform Matching ---
                        with st.spinner("‚è≥ Matching patients..."):
                            df_matched, msg = psm_lib.perform_matching(df_ps, final_treat_col, 'ps_logit', caliper)
                        
                        if df_matched is None:
                            st.error(f"‚ùå Matching failed: {msg}")
                        else:
                            # Calculate SMD (including categorical)
                            smd_pre = psm_lib.calculate_smd(df_ps, final_treat_col, final_cov_cols)
                            smd_post = psm_lib.calculate_smd(df_matched, final_treat_col, final_cov_cols)
                            
                            # üü¢ NEW: Add categorical SMD (cat_covs is guaranteed to exist now)
                            smd_pre_cat = _calculate_categorical_smd(df_ps, final_treat_col, cat_covs)
                            smd_post_cat = _calculate_categorical_smd(df_matched, final_treat_col, cat_covs)
                            
                            smd_pre = pd.concat([smd_pre, smd_pre_cat], ignore_index=True)
                            smd_post = pd.concat([smd_post, smd_post_cat], ignore_index=True)
                            
                            st.success(f"‚úÖ {msg}")
                            
                            # Store in session
                            st.session_state.df_matched = df_matched
                            st.session_state.is_matched = True
                            st.session_state.matched_treatment_col = treat_col
                            st.session_state.matched_covariates = cov_cols
                            logger.info("üíæ Matched data stored. Rows: %d", len(df_matched))
                            
                            st.divider()
                            
                            # ==========================================
                            # üü¢ PRIORITY 1: QUALITY METRICS DASHBOARD
                            # ==========================================
                            st.subheader("Step 3Ô∏è‚É£: Match Quality Summary")
                            
                            treated_before = df_ps[final_treat_col].sum()
                            match_rate = (df_matched[final_treat_col].sum() / treated_before * 100) if treated_before > 0 else 0
                            good_balance_count = (smd_post['SMD'] < 0.1).sum()
                            
                            m_col1, m_col2, m_col3, m_col4 = st.columns(4)
                            
                            with m_col1:
                                st.metric(
                                    label="Pairs Matched",
                                    value=f"{df_matched[final_treat_col].sum():.0f}",
                                    delta=f"({match_rate:.1f}% of {df_ps[final_treat_col].sum():.0f})" 
                                )
                            
                            with m_col2:
                                st.metric(
                                    label="Sample Retained",
                                    value=f"{len(df_matched):,}",
                                    delta=f"({len(df_matched)/len(df_ps)*100:.1f}% of {len(df_ps):,})"
                                )
                            
                            with m_col3:
                                st.metric(
                                    label="Good Balance",
                                    value=f"{good_balance_count}/{len(smd_post)}",
                                    delta="(SMD < 0.1)" if good_balance_count == len(smd_post) else f"‚ö†Ô∏è {len(smd_post) - good_balance_count} vars"
                                )
                            
                            with m_col4:
                                # üü¢ FIX: Correct column name suffixes (no leading space)
                                smd_merge_qual = smd_pre.merge(smd_post, on='Variable', suffixes=('_pre', '_post'))
                                avg_smd_before = smd_merge_qual['SMD_pre'].mean()
                                avg_smd_after = smd_merge_qual['SMD_post'].mean()
                                improvement = ((avg_smd_before - avg_smd_after) / avg_smd_before * 100) if avg_smd_before > 0 else 0
                                
                                st.metric(
                                    label="SMD Improvement",
                                    value=f"{improvement:.1f}%",
                                    delta="‚Üì average reduction"
                                )
                            
                            # Balance warning
                            if (smd_post['SMD'] > 0.1).any():
                                bad_vars = smd_post[smd_post['SMD'] > 0.1]['Variable'].tolist()
                                st.warning(f"""
                                ‚ö†Ô∏è **Imbalance remains on {len(bad_vars)} variable(s):**
                                
                                {', '.join(bad_vars[:5])}{'...' if len(bad_vars) > 5 else ''}
                                
                                **Try:** Increase caliper width or check for outliers
                                """, icon="‚ö†Ô∏è")
                            else:
                                st.success("‚úÖ **Excellent balance achieved!** All variables have SMD < 0.1", icon="‚úÖ")
                            
                            st.divider()
                            
                            # Balance Check Tabs
                            st.subheader("Step 4Ô∏è‚É£: Balance Assessment")
                            
                            bal_tab1, bal_tab2, bal_tab3 = st.tabs([
                                "üìâ Love Plot",
                                "üìã SMD Table",
                                "üìä Group Comparison"
                            ])
                            
                            with bal_tab1:
                                fig_love = psm_lib.plot_love_plot(smd_pre, smd_post)
                                st.plotly_chart(fig_love, use_container_width=True)
                                st.caption("Green (diamond) = matched, Red (circle) = unmatched. Target: All on left (SMD < 0.1)")
                            
                            with bal_tab2:
                                # üü¢ FIX: Correct column name suffixes (no leading space)
                                smd_merge_display = smd_pre.merge(smd_post, on='Variable', suffixes=('_before', '_after'))
                                # Guard against division by zero
                                smd_merge_display['Improvement %'] = (
                                    ((smd_merge_display['SMD_before'] - smd_merge_display['SMD_after']) / 
                                    smd_merge_display['SMD_before'].replace(0, np.nan) * 100)
                                    .round(1)
                                    .fillna(0)
                                )
                                
                                # üü¢ FIX: Use simpler styling without colormap to avoid 'ColormapRegistry' error
                                st.dataframe(
                                    smd_merge_display.style.format({
                                        'SMD_before': '{:.4f}',
                                        'SMD_after': '{:.4f}',
                                        'Improvement %': '{:.1f}%'
                                    }).highlight_min(subset=['SMD_after'], color='lightgreen'),
                                    use_container_width=True
                                )
                                st.caption("‚úÖ Good balance: SMD < 0.1 after matching")
                            
                            with bal_tab3:
                                st.write("**Group sizes before and after matching:**")
                                comp_data = pd.DataFrame({
                                    'Stage': ['Before', 'After'],
                                    f'{target_val or "Treated (1)"}': [
                                        (df_ps[final_treat_col] == 1).sum(),
                                        (df_matched[final_treat_col] == 1).sum()
                                    ],
                                    'Control (0)': [
                                        (df_ps[final_treat_col] == 0).sum(),
                                        (df_matched[final_treat_col] == 0).sum()
                                    ]
                                })
                                st.dataframe(comp_data, use_container_width=True)
                            
                            st.divider()
                            
                            # Export Options
                            st.subheader("Step 5Ô∏è‚É£: Export & Next Steps")
                            
                            col_exp1, col_exp2, col_exp3 = st.columns(3)
                            
                            with col_exp1:
                                csv_data = df_matched.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    "üì• Download CSV",
                                    csv_data,
                                    "matched_data.csv",
                                    "text/csv",
                                    use_container_width=True
                                )
                            
                            with col_exp2:
                                elements = [
                                    {'type': 'text', 'data': f"PSM Report - {treat_col}"},
                                    {'type': 'table', 'data': smd_merge_display},
                                    {'type': 'plot', 'data': fig_love}
                                ]
                                html_rep = psm_lib.generate_psm_report("Propensity Score Matching Report", elements)
                                st.download_button(
                                    "üì• Report HTML",
                                    html_rep,
                                    "psm_report.html",
                                    "text/html",
                                    use_container_width=True
                                )
                            
                            with col_exp3:
                                st.info("‚úÖ Full matched data available in **Subtab 3 (Matched Data View)**")
                            
                except Exception as e:
                    st.error(f"‚ùå Error: {e!s}")
                    logger.exception("PSM analysis failed")

    # ==========================================
    # SUBTAB 3: MATCHED DATA VIEW
    # ==========================================
    with sub_tab3:
        st.markdown("##### ‚úÖ Matched Data View & Export")
        
        if st.session_state.get("is_matched", False) and st.session_state.get("df_matched") is not None:
            df_m = st.session_state.df_matched
            
            st.success(f"""
            ‚úÖ **Matched Dataset Ready**
            - Total rows: **{len(df_m)}**
            - Original rows: **{len(df)}**
            - Excluded: **{len(df) - len(df_m)}** rows
            - Treatment variable: **{st.session_state.matched_treatment_col}**
            """)
            
            # Summary Statistics
            with st.expander("üìä Summary Statistics", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**Group Sizes:**")
                    if st.session_state.matched_treatment_col in df_m.columns:
                        grp_counts = df_m[st.session_state.matched_treatment_col].value_counts().sort_index()
                        st.write(grp_counts)
                with col2:
                    st.markdown("**Data Types:**")
                    dtype_counts = df_m.dtypes.astype(str).value_counts()
                    st.write(dtype_counts)
            
            # Data Filter & Preview
            with st.expander("üîç Filter & Preview", expanded=True):
                total_rows = len(df_m)

                # Unified slider logic
                min_rows = min(10, total_rows)
                max_rows = total_rows
                default_rows = min(50, max_rows)
                step = 1 if max_rows < 20 else 10
                
                n_display = st.slider(
                    "Rows to display:",
                    min_value=min_rows,
                    max_value=max_rows,
                    value=default_rows,
                    step=step,
                    disabled=(total_rows <= 10),
                    key="matched_data_rows_slider"
                )
                
                if total_rows <= 10:
                    st.caption(f"Showing all {total_rows} rows")

                st.dataframe(df_m.head(n_display), use_container_width=True, height=400)

            # Download Options
            st.markdown("### üì• Export Matched Data")
            col_csv, col_txt = st.columns(2)
            
            with col_csv:
                csv_data = df_m.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• CSV Format",
                    data=csv_data,
                    file_name="matched_data.csv",
                    mime="text/csv",
                    key="dl_matched_csv_view"
                )
            
            with col_txt:
                try:
                    import openpyxl
                    from io import BytesIO
                    
                    buffer = BytesIO()
                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                        df_m.to_excel(writer, sheet_name='Matched Data', index=False)
                    
                    st.download_button(
                        label="üì• Excel Format",
                        data=buffer.getvalue(),
                        file_name="matched_data.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key="dl_matched_xlsx_view"
                    )
                except ImportError:
                    logger.debug("openpyxl not available for Excel export")
                    st.info("üí° Excel export requires openpyxl package")
            
            # Statistics by Treatment Group
            st.markdown("### üìà Statistics by Group")
            if st.session_state.matched_treatment_col in df_m.columns:
                treat_col_m = st.session_state.matched_treatment_col
                
                numeric_cols = df_m.select_dtypes(include=[np.number]).columns.tolist()
                numeric_cols = [c for c in numeric_cols if c != treat_col_m]
                
                if numeric_cols:
                    selected_col = st.selectbox("Select numeric variable to compare:", numeric_cols, key='matched_numeric_select')
                    
                    summary_tab1, summary_tab2 = st.tabs([
                        "üìä Descriptive Stats",
                        "üìâ Visualization"
                    ])
                    
                    with summary_tab1:
                        summary_stats = df_m.groupby(treat_col_m)[selected_col].describe()
                        st.dataframe(summary_stats, use_container_width=True)
                    
                    with summary_tab2:
                        fig = px.box(df_m, x=treat_col_m, y=selected_col, title=f"{selected_col} by {treat_col_m}")
                        st.plotly_chart(fig, use_container_width=True)
            
            # Reset Button
            if st.button("üîÑ Clear Matched Data & Return to Analysis", type="secondary", key='btn_clear_matched'):
                st.session_state.df_matched = None
                st.session_state.is_matched = False
                st.session_state.matched_treatment_col = None
                st.session_state.matched_covariates = []
                logger.info("üîÑ Matched data cleared")
                st.rerun()
        else:
            st.info("""
            ‚ÑπÔ∏è **No matched data available yet.**
            
            1. Go to **Subtab 2 (Propensity Score Matching)**
            2. Configure variables and run PSM matching
            3. Return here to view and export matched data
            """)

    # ==========================================
    # SUBTAB 4: REFERENCE & INTERPRETATION (Updated)
    # ==========================================
    with sub_tab4:
        st.markdown("## üìö Reference & Interpretation Guide")
        
        st.info("üí° **Tip:** This section provides detailed explanations and interpretation rules for Table 1 and Propensity Score Matching.")
        
        # üí° Decision Guide (First for quick access)
        st.markdown("### üö¶ Quick Decision Guide")
        st.markdown("""
        | **Question** | **Recommended Action** | **Goal** |
        | :--- | :--- | :--- |
        | Do my groups (e.g., Treated vs Control) differ at baseline? | **Generate Table 1** (Tab 1) | Check for significant p-values (< 0.05). |
        | My groups are imbalanced (p < 0.05 in Table 1). Can I fix this? | **Run PSM** (Tab 2) | Create a "synthetic" RCT where groups are balanced. |
        | Did the matching work? | **Check SMD** (Tab 2 - Results) | Look for **SMD < 0.1** in the Love Plot. |
        | Now that I have matched data, what do I do? | **Export / Use Matched Data** | Go to **Tab 3** to export, or select "‚úÖ Matched Data" in other analysis tabs. |
        """)
        
        st.divider()

        col1, col2 = st.columns(2)
        
        # --- Column 1: Table 1 ---
        with col1:
            st.markdown("### üìä Baseline Characteristics (Table 1)")
            st.markdown("""
            **Concept:** A standard table in medical research that compares the demographic and clinical characteristics of two or more groups (e.g., Treatment vs Placebo).
            
            **Interpretation:**
            * **P-value:** Tests if there is a statistically significant difference between groups.
                * **p < 0.05:** Significant difference (Imbalance) ‚ö†Ô∏è. This suggests confounding may be present.
                * **p ‚â• 0.05:** No significant difference (Balanced) ‚úÖ.
            
            **Reporting Standards:**
            * **Numeric Data (Normal):** Report **Mean ¬± SD**. (e.g., Age: 45.2 ¬± 10.1)
            * **Numeric Data (Skewed):** Report **Median (IQR)**. (e.g., LOS: 5 (3-10))
            * **Categorical Data:** Report **Count (%)**. (e.g., Male: 50 (45%))
            """)
            
        # --- Column 2: PSM ---
        with col2:
            st.markdown("### ‚öñÔ∏è Propensity Score Matching (PSM)")
            st.markdown("""
            **Concept:** A statistical technique used in observational studies to reduce selection bias. It pairs patients in the treated group with patients in the control group who have similar "propensity scores" (probability of receiving treatment).
            
            **Key Metric: Standardized Mean Difference (SMD):**
            * The gold standard for checking balance after matching.
            * **SMD < 0.1:** Excellent Balance ‚úÖ (Groups are comparable).
            * **SMD 0.1 - 0.2:** Acceptable.
            * **SMD > 0.2:** Imbalanced ‚ùå.
            
            **Caliper (Tolerance):**
            * Determines how "close" a match must be.
            * **Stricter (0.1*SD):** Better balance, but you might lose more patients (fewer matches).
            * **Looser (0.5*SD):** More matches, but balance might be worse.
            """)

        st.markdown("---")
        st.markdown("### üìù Common Workflow")
        st.markdown("""
        1.  **Check Original Data:** Run Table 1 on the "Original Data". Note any variables with p < 0.05.
        2.  **Match:** Go to PSM, select Treatment, Outcome, and **all confounding variables** (especially those with p < 0.05).
        3.  **Verify:** After matching, check the **Love Plot**. Ensure all dots (Matched) are within the < 0.1 zone.
        4.  **Re-check Table 1:** Go back to Tab 1, switch the dataset selector to **"‚úÖ Matched Data"**, and generate Table 1 again. P-values should now be non-significant (or SMDs low).
        """)


def _calculate_categorical_smd(
    df: pd.DataFrame,
    treatment_col: str,
    cat_cols: list
) -> pd.DataFrame:
    """
    Compute standardized mean differences (SMD) for categorical covariates between treated and control groups.
    """
    if not cat_cols:
        return pd.DataFrame(columns=['Variable', 'SMD'])
    
    smd_data = []
    treated = df[df[treatment_col] == 1]
    control = df[df[treatment_col] == 0]
    
    n_treated = len(treated)
    n_control = len(control)
    
    # Handle edge case: if one group is empty
    if n_treated == 0 or n_control == 0:
        logger.warning("One treatment group is empty. Cannot calculate categorical SMD.")
        return pd.DataFrame(columns=['Variable', 'SMD'])
    
    for col in cat_cols:
        try:
            categories = df[col].dropna().unique()
            smd_squared_sum = 0
            
            for cat in categories:
                # Calculate proportions for each group
                p_treated = (treated[col] == cat).sum() / n_treated
                p_control = (control[col] == cat).sum() / n_control
                
                # Calculate pooled proportion (weighted average)
                p_pooled = (n_treated * p_treated + n_control * p_control) / (n_treated + n_control)
                
                # Calculate variance with regularization to avoid division by zero
                # Add small epsilon (1e-8) to handle edge cases
                variance = p_pooled * (1 - p_pooled) + 1e-8
                
                # Calculate SMD for this level
                smd_level = (p_treated - p_control) / np.sqrt(variance)
                
                # Accumulate squared SMDs (for root-sum-square aggregation)
                smd_squared_sum += smd_level ** 2
            
            # Aggregate SMD across all levels using root-sum-square
            # This is the standard approach for multi-level categorical variables
            smd = np.sqrt(smd_squared_sum)
            smd_data.append({'Variable': col, 'SMD': smd})
            
        except (KeyError, TypeError, ZeroDivisionError) as e:
            logger.warning("Error calculating categorical SMD for %s: %s", col, e)
            continue
    
    return pd.DataFrame(smd_data)
