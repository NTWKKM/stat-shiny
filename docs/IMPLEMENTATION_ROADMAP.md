# ðŸš€ à¸ªà¸£à¸¸à¸›à¹à¸™à¸§à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚

à¹‚à¸„à¹‰à¸”à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸¡à¸µà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸—à¸µà¹ˆà¸”à¸µà¹à¸¥à¹‰à¸§à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£ *à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š (Detection)* à¹à¸•à¹ˆà¸¢à¸±à¸‡à¸‚à¸²à¸”à¸ªà¹ˆà¸§à¸™à¸‚à¸­à¸‡ *à¸à¸²à¸£à¹à¸à¹‰à¹„à¸‚ (Treatment)* à¹à¸¥à¸° *à¸à¸²à¸£à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (Transformation)* à¹à¸šà¸šà¹‚à¸•à¹‰à¸•à¸­à¸šà¹„à¸”à¹‰ à¸™à¸µà¹ˆà¸„à¸·à¸­à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¹€à¸žà¸´à¹ˆà¸¡:

1. **Backend (`utils/data_cleaning.py`)**: à¹€à¸žà¸´à¹ˆà¸¡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸ªà¸³à¸«à¸£à¸±à¸š Imputation (à¹à¸—à¸™à¸—à¸µà¹ˆà¸„à¹ˆà¸²à¸§à¹ˆà¸²à¸‡), Transformation (Log, Box-Cox) à¹à¸¥à¸° Assumption Testing
2. **Frontend (`tabs/tab_data.py`)**: à¸›à¸£à¸±à¸š UI à¸ˆà¸²à¸à¸—à¸µà¹ˆà¹à¸„à¹ˆ "à¸”à¸¹" à¹ƒà¸«à¹‰à¸¡à¸µà¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸¡à¸·à¸­ "à¸à¸£à¸°à¸—à¸³" (Action Buttons) à¹à¸¢à¸à¹€à¸›à¹‡à¸™à¸«à¸¡à¸§à¸”à¸«à¸¡à¸¹à¹ˆ

---

### Step 1: à¸­à¸±à¸›à¹€à¸à¸£à¸” Backend Logic (`utils/data_cleaning.py`)

à¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¹€à¸žà¸´à¹ˆà¸¡à¹„à¸¥à¸šà¸£à¸²à¸£à¸µ `sklearn` à¹à¸¥à¸° `scipy` à¹€à¸‚à¹‰à¸²à¹„à¸›à¹€à¸žà¸·à¹ˆà¸­à¸£à¸­à¸‡à¸£à¸±à¸š MICE, KNN à¹à¸¥à¸° Statistical Tests à¹€à¸žà¸´à¹ˆà¸¡à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¸•à¹ˆà¸­à¸—à¹‰à¸²à¸¢à¹„à¸Ÿà¸¥à¹Œà¹€à¸”à¸´à¸¡:

```python
# à¹€à¸žà¸´à¹ˆà¸¡ Import à¸—à¸µà¹ˆà¸«à¸±à¸§à¹„à¸Ÿà¸¥à¹Œ utils/data_cleaning.py
from sklearn.impute import KNNImputer
from sklearn.experimental import enable_iterative_imputer  # noqa
from sklearn.impute import IterativeImputer
from scipy import stats

# ... (à¹‚à¸„à¹‰à¸”à¹€à¸”à¸´à¸¡) ...

# 1. à¹€à¸žà¸´à¹ˆà¸¡ Class/Function à¸ªà¸³à¸«à¸£à¸±à¸š Advanced Imputation
def impute_missing_data(
    df: pd.DataFrame, 
    cols: list[str], 
    method: str = 'knn', 
    **kwargs
) -> pd.DataFrame:
    """
    Impute missing values using advanced strategies.
    Methods: 'mean', 'median', 'knn', 'mice'
    """
    df_out = df.copy()
    
    # Select only numeric columns for advanced imputation
    numeric_df = df_out[cols].select_dtypes(include=[np.number])
    if numeric_df.empty:
        return df_out

    try:
        if method == 'knn':
            n_neighbors = kwargs.get('n_neighbors', 5)
            imputer = KNNImputer(n_neighbors=n_neighbors)
            df_out[numeric_df.columns] = imputer.fit_transform(numeric_df)
            
        elif method == 'mice':
            imputer = IterativeImputer(random_state=42, max_iter=10)
            df_out[numeric_df.columns] = imputer.fit_transform(numeric_df)
            
        elif method in ['mean', 'median']:
            for col in numeric_df.columns:
                val = numeric_df[col].mean() if method == 'mean' else numeric_df[col].median()
                df_out[col] = df_out[col].fillna(val)
                
        logger.info(f"Imputed missing data using {method} on {len(cols)} columns")
        return df_out
        
    except Exception as e:
        logger.error(f"Imputation failed: {e}")
        raise DataCleaningError(f"Imputation failed: {e}")

# 2. à¹€à¸žà¸´à¹ˆà¸¡ Function à¸ªà¸³à¸«à¸£à¸±à¸š Variable Transformation
def transform_variable(
    series: pd.Series, 
    method: str = 'log'
) -> pd.Series:
    """
    Apply statistical transformations.
    Methods: 'log', 'sqrt', 'zscore', 'minmax'
    """
    clean_s = clean_numeric_vector(series)
    
    try:
        if method == 'log':
            # Handle zeros/negative for log
            if (clean_s <= 0).any():
                # Shift if negative
                shift = abs(clean_s.min()) + 1
                return np.log(clean_s + shift)
            return np.log(clean_s)
            
        elif method == 'sqrt':
            return np.sqrt(clean_s.clip(lower=0))
            
        elif method == 'zscore':
            return (clean_s - clean_s.mean()) / clean_s.std()
            
        else:
            return clean_s
            
    except Exception as e:
        logger.error(f"Transformation {method} failed: {e}")
        return series

# 3. à¹€à¸žà¸´à¹ˆà¸¡ Function Assumption Testing
def check_assumptions(series: pd.Series) -> dict[str, Any]:
    """
    Check normality and other statistical assumptions.
    """
    clean_s = clean_numeric_vector(series).dropna()
    if len(clean_s) < 3:
        return {"normality": "Insufficient Data"}
        
    # Shapiro-Wilk (N < 5000) or Kolmogorov-Smirnov
    stat, p_val = stats.shapiro(clean_s) if len(clean_s) < 5000 else stats.kstest(clean_s, 'norm')
    
    return {
        "normality_test": "Shapiro-Wilk" if len(clean_s) < 5000 else "K-S Test",
        "statistic": round(stat, 4),
        "p_value": round(p_val, 4),
        "is_normal": p_val > 0.05
    }

```

---

### Step 2: à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡ UI (`tabs/tab_data.py`)

à¸›à¸£à¸±à¸šà¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸™ `data_ui` à¹‚à¸”à¸¢à¹€à¸žà¸´à¹ˆà¸¡ **Tabset** à¸«à¸£à¸·à¸­ **Accordion** à¹à¸¢à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡ à¹€à¸žà¸·à¹ˆà¸­à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¸«à¸™à¹‰à¸²à¸ˆà¸­à¸£à¸à¸£à¸¸à¸‡à¸£à¸±à¸‡

```python
# à¹ƒà¸™à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ data_ui() ...
# à¹à¸—à¸™à¸—à¸µà¹ˆà¸ªà¹ˆà¸§à¸™ ui.accordion à¹€à¸”à¸´à¸¡ à¸«à¸£à¸·à¸­à¹€à¸žà¸´à¹ˆà¸¡à¸•à¹ˆà¸­à¸—à¹‰à¸²à¸¢à¸”à¹‰à¸§à¸¢ Section à¹ƒà¸«à¸¡à¹ˆ:

ui.navset_card_tab(
    # Tab 1: Configuration (à¸­à¸±à¸™à¹€à¸”à¸´à¸¡à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ)
    ui.nav_panel("ðŸ› ï¸ Variable Config", 
        ui.accordion(
            # ... (Accordion à¹€à¸”à¸´à¸¡à¸‚à¸­à¸‡à¸„à¸¸à¸“: Variable Selection, Missing Codes) ...
             ui.accordion_panel(
                ui.tags.span("ðŸ“ Metadata & Type", class_="fw-bold"),
                # ... (UI à¹€à¸”à¸´à¸¡à¸ªà¸³à¸«à¸£à¸±à¸š Type/Map) ...
                value="var_config"
            ),
            open=True
        )
    ),
    
    # Tab 2: [NEW] Advanced Cleaning & Imputation
    ui.nav_panel("ðŸ§¹ Cleaning & Imputation",
        ui.layout_columns(
            # Card 1: Missing Data Imputation
            ui.card(
                ui.card_header("ðŸ§© Impute Missing Data"),
                ui.input_select("sel_impute_method", "Method:", 
                    choices=["mean", "median", "knn", "mice"]),
                ui.input_select("sel_impute_cols", "Columns:", choices=[], multiple=True),
                ui.input_action_button("btn_run_impute", "Run Imputation", 
                    class_="btn-warning")
            ),
            
            # Card 2: Outlier Treatment
            ui.card(
                ui.card_header("graph-up-arrow Outlier Handling"),
                ui.input_select("sel_outlier_action", "Action:", 
                    choices=["flag", "remove", "winsorize", "cap"]),
                ui.input_numeric("num_outlier_thresh", "Threshold (IQR/Z):", value=1.5, step=0.1),
                ui.input_action_button("btn_run_outlier", "Handle Outliers", 
                    class_="btn-danger")
            ),
            col_widths=(6, 6)
        )
    ),
    
    # Tab 3: [NEW] Transformation & Assumptions
    ui.nav_panel("transform Transformation",
        ui.layout_columns(
            ui.div(
                ui.input_select("sel_trans_var", "Variable:", choices=["Select..."]),
                ui.input_select("sel_trans_method", "Transformation:", 
                    choices=["log", "sqrt", "zscore"]),
                ui.input_action_button("btn_run_trans", "Apply Transform", 
                    class_="btn-primary w-100 mb-3"),
                
                ui.h6("ðŸ“Š Assumption Check"),
                ui.output_ui("ui_assumption_result")
            ),
            ui.div(
                # à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆà¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸£à¸²à¸Ÿ Before/After
                ui.output_plot("plot_trans_preview")
            ),
            col_widths=(4, 8)
        )
    )
)

```

---

### Step 3: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­ Server Logic (`tabs/tab_data.py`)

à¹€à¸žà¸´à¹ˆà¸¡ Logic à¹ƒà¸™ `data_server` à¹€à¸žà¸·à¹ˆà¸­à¸£à¸­à¸‡à¸£à¸±à¸šà¸›à¸¸à¹ˆà¸¡à¸à¸”à¹ƒà¸«à¸¡à¹ˆà¹†:

```python
# à¹ƒà¸™ data_server ...

# 1. Update Choice lists (à¹€à¸¡à¸·à¹ˆà¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™ à¹ƒà¸«à¹‰ update dropdown à¸‚à¸­à¸‡ imputation/transformation à¸”à¹‰à¸§à¸¢)
@reactive.Effect
def _update_cleaning_choices():
    data = df.get()
    if data is not None:
        numeric_cols = data.select_dtypes(include=np.number).columns.tolist()
        ui.update_select("sel_impute_cols", choices=numeric_cols)
        ui.update_select("sel_trans_var", choices=["Select...", *numeric_cols])

# 2. Handle Imputation
@reactive.Effect
@reactive.event(input.btn_run_impute)
def _handle_imputation():
    from utils.data_cleaning import impute_missing_data # Import function à¹ƒà¸«à¸¡à¹ˆ
    
    d = df.get()
    cols = input.sel_impute_cols()
    method = input.sel_impute_method()
    
    if d is not None and cols:
        try:
            new_df = impute_missing_data(d, list(cols), method=method)
            df.set(new_df) # Update Reactive DataFrame
            ui.notification_show(f"âœ… Imputed {len(cols)} columns using {method}", type="message")
        except Exception as e:
            ui.notification_show(f"âŒ Imputation failed: {e}", type="error")

# 3. Handle Transformation & Assumption Check
@render.ui
def ui_assumption_result():
    var_name = input.sel_trans_var()
    d = df.get()
    
    if d is None or var_name == "Select...": 
        return None
        
    from utils.data_cleaning import check_assumptions
    res = check_assumptions(d[var_name])
    
    color = "green" if res['is_normal'] else "red"
    return ui.div(
        ui.p(f"Test: {res['normality_test']}"),
        ui.p(f"P-Value: {res['p_value']}", style=f"color: {color}; font-weight: bold;"),
        ui.p("Distribution is Normal" if res['is_normal'] else "Distribution is NOT Normal"),
        class_="alert alert-light border shadow-sm"
    )

@reactive.Effect
@reactive.event(input.btn_run_trans)
def _handle_transform():
    # Logic à¸„à¸¥à¹‰à¸²à¸¢ Imputation: à¹€à¸£à¸µà¸¢à¸ transform_variable -> update df -> notify
    pass

```

### à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

* **Data Integrity**: à¸à¸²à¸£à¸—à¸³ Imputation à¸«à¸£à¸·à¸­ Transformation à¸ˆà¸°à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸£à¸´à¸‡ (`df.set(new_df)`) à¸”à¸±à¸‡à¸™à¸±à¹‰à¸™à¸„à¸§à¸£à¸¡à¸µà¸›à¸¸à¹ˆà¸¡ **Undo** à¸«à¸£à¸·à¸­à¹ƒà¸Šà¹‰à¸£à¸°à¸šà¸š Versioning à¸­à¸¢à¹ˆà¸²à¸‡à¸‡à¹ˆà¸²à¸¢ (à¹€à¸Šà¹ˆà¸™ à¹€à¸à¹‡à¸š `df_history = reactive.Value([])`) à¸«à¸²à¸ user à¸—à¸³à¸žà¸¥à¸²à¸”à¸ˆà¸°à¹„à¸”à¹‰à¸¢à¹‰à¸­à¸™à¸à¸¥à¸±à¸šà¹„à¸”à¹‰
* **Requirements**: à¸­à¸¢à¹ˆà¸²à¸¥à¸·à¸¡ update `requirements.txt` à¹ƒà¸«à¹‰à¸¡à¸µ `scikit-learn>=1.3.0` à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸à¹ƒà¸™ Roadmap à¸”à¹‰à¸§à¸¢à¸„à¸£à¸±à¸š
