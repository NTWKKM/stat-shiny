# üîß ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Table One Generator

## üéØ ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç

### 1. ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: `get_stats_categorical_str` ‡∏£‡∏±‡∏ö Series ‡πÅ‡∏ï‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á dict

**Root Cause:**
```python
# ‡πÉ‡∏ô generate_table() ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î 584-586
counts_g, n_g, _ = get_stats_categorical_data(sub_df[col], var_meta, col)
val_g = get_stats_categorical_str(counts_g, n_g)  
# ‚ùå counts_g ‡∏Ñ‡∏∑‡∏≠ pd.Series ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà dict
```

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
def get_stats_categorical_str(
    counts: Union[pd.Series, Dict[Any, int]], 
    total: int
) -> str:
    """‚úÖ FIXED: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Series ‡πÅ‡∏•‡∏∞ dict"""
    
    # ‚úÖ Convert dict to Series if needed
    if isinstance(counts, dict):
        counts = pd.Series(counts)
    
    # ‚úÖ Validate input type
    if not isinstance(counts, pd.Series):
        logger.error(f"Invalid counts type: {type(counts)}")
        return "-"
    
    # ‚úÖ Handle empty data
    if len(counts) == 0:
        return "-"
    
    # ‚úÖ Safe percentage calculation
    if total > 0:
        pcts = (counts / total * 100)
    else:
        pcts = pd.Series([0] * len(counts), index=counts.index)
    
    # ‚úÖ Format with error handling
    try:
        res = [
            f"{_html.escape(str(cat))}: {int(count)} ({pct:.1f}%)" 
            for cat, count, pct in zip(
                counts.index, 
                counts.values, 
                pcts.values, 
                strict=True
            )
        ]
        return "<br>".join(res)
    except Exception as e:
        logger.error(f"Error formatting categorical stats: {e}")
        return "-"
```

---

### 2. ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Data Cleaning ‡πÑ‡∏°‡πà‡∏°‡∏µ Validation

**Root Cause:**
```python
# ‡πÄ‡∏î‡∏¥‡∏°: ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ cleaning ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
df_cleaned, cleaning_report = clean_dataframe(df, ...)
df = df_cleaned  # ‚ùå ‡∏ñ‡πâ‡∏≤ df_cleaned = None ‡∏à‡∏∞ error
```

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
def generate_table(...) -> str:
    """‚úÖ FIXED: Enhanced validation and error handling"""
    
    logger.info("Creating cleaned copy for statistical analysis...")
    
    try:
        df_cleaned, cleaning_report = clean_dataframe(
            df,
            handle_outliers_flag=False,
            validate_quality=True
        )
        
        # ‚úÖ Validate cleaning success
        if df_cleaned is None or df_cleaned.empty:
            raise ValueError("Data cleaning failed: resulted in empty DataFrame")
        
        logger.info(f"Original: {df.shape}, Cleaned: {df_cleaned.shape}")
        logger.debug(f"Cleaning summary: {cleaning_report.get('summary', {})}")
        
        # ‚úÖ Check data quality warnings
        if 'quality_report' in cleaning_report:
            quality = cleaning_report['quality_report']['summary']
            if quality.get('has_errors', False):
                logger.warning("Data quality issues - results may be unreliable")
        
    except Exception as e:
        logger.error(f"Data cleaning failed: {e}")
        raise ValueError(f"Cannot generate table: data cleaning error - {e}")
    
    # ‚úÖ Now safe to use cleaned data
    df = df_cleaned
```

---

### 3. ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡πÑ‡∏°‡πà validate column existence

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
# ‚úÖ Validate group column
if has_group:
    if group_col not in df.columns:
        raise ValueError(f"Group column '{group_col}' not found in data")
    
    raw_groups = df[group_col].dropna().unique().tolist()
    
    # ‚úÖ Validate we have groups
    if len(raw_groups) == 0:
        raise ValueError(f"No valid groups found in column '{group_col}'")

# ‚úÖ Validate each variable column
for col in selected_vars:
    if col not in df.columns:
        logger.warning(f"Column '{col}' not found - skipping")
        continue
```

---

### 4. ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Error ‡πÉ‡∏ô loop ‡∏ó‡∏≥‡πÉ‡∏´‡πâ table ‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå

**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
for col in selected_vars:
    try:
        # ‚úÖ Process column with error handling
        if is_cat:
            counts_total, n_total, mapped_full_series = get_stats_categorical_data(...)
            val_total = get_stats_categorical_str(counts_total, n_total)
        else:
            val_total = get_stats_continuous(df[col])
        
        # ... rest of processing ...
        
    except Exception as e:
        logger.error(f"Error processing column '{col}': {e}")
        # ‚úÖ Skip this column and continue (don't break entire table)
        continue
```

---

## üß™ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏î‡∏™‡∏≠‡∏ö (Testing Guide)

### Test Case 1: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Categorical Variables

```python
import pandas as pd
import numpy as np
from table_one import generate_table

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
np.random.seed(42)
df_test = pd.DataFrame({
    'Treatment_Group': np.random.binomial(1, 0.5, 100),
    'Sex': np.random.binomial(1, 0.5, 100),
    'Diabetes': np.random.binomial(1, 0.3, 100),
    'Age': np.random.normal(60, 10, 100)
})

var_meta = {
    'Treatment_Group': {
        'type': 'Categorical',
        'map': {0: 'Control', 1: 'Treatment'},
        'label': 'Treatment Group'
    },
    'Sex': {
        'type': 'Categorical',
        'map': {0: 'Female', 1: 'Male'},
        'label': 'Sex'
    },
    'Diabetes': {
        'type': 'Categorical',
        'map': {0: 'No', 1: 'Yes'},
        'label': 'Diabetes'
    }
}

# ‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ generate table
html = generate_table(
    df=df_test,
    selected_vars=['Age', 'Sex', 'Diabetes'],
    group_col='Treatment_Group',
    var_meta=var_meta,
    or_style='all_levels'
)

print("‚úÖ Test Case 1 PASSED" if html else "‚ùå Test Case 1 FAILED")
```

### Test Case 2: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Missing Data

```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ missing values
df_test_missing = df_test.copy()
df_test_missing.loc[0:20, 'Age'] = np.nan
df_test_missing.loc[10:30, 'Sex'] = np.nan

try:
    html = generate_table(
        df=df_test_missing,
        selected_vars=['Age', 'Sex', 'Diabetes'],
        group_col='Treatment_Group',
        var_meta=var_meta
    )
    print("‚úÖ Test Case 2 PASSED - Handles missing data")
except Exception as e:
    print(f"‚ùå Test Case 2 FAILED: {e}")
```

### Test Case 3: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Edge Cases

```python
# Test 3.1: Empty groups
df_empty_group = df_test.copy()
df_empty_group['Treatment_Group'] = 0  # ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß

try:
    html = generate_table(
        df=df_empty_group,
        selected_vars=['Age', 'Sex'],
        group_col='Treatment_Group',
        var_meta=var_meta
    )
    print("‚úÖ Test 3.1 PASSED")
except ValueError as e:
    print(f"‚úÖ Test 3.1 PASSED - Caught expected error: {e}")

# Test 3.2: Non-existent column
try:
    html = generate_table(
        df=df_test,
        selected_vars=['Age', 'NonExistentColumn'],
        group_col='Treatment_Group',
        var_meta=var_meta
    )
    print("‚úÖ Test 3.2 PASSED - Skipped non-existent column")
except Exception as e:
    print(f"‚ùå Test 3.2 FAILED: {e}")

# Test 3.3: All missing in column
df_all_missing = df_test.copy()
df_all_missing['Age'] = np.nan

html = generate_table(
    df=df_all_missing,
    selected_vars=['Age', 'Sex'],
    group_col='Treatment_Group',
    var_meta=var_meta
)
print("‚úÖ Test 3.3 PASSED - Handled all-missing column")
```

---

## üîç ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Logs

### Log Levels ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏î‡∏π:

```python
# ‚úÖ Success logs
INFO: Creating cleaned copy for statistical analysis...
INFO: Original data: (1500, 18), Cleaned data: (1500, 18)
DEBUG: Cleaning summary: {'total_rows': 1500, 'overall_missing_pct': 0.0}

# ‚ö†Ô∏è Warning logs (‡πÑ‡∏°‡πà fatal ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏£‡∏π‡πâ)
WARNING: Data quality issues detected - results may be unreliable
WARNING: Column 'XYZ' not found in data - skipping

# ‚ùå Error logs (‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ)
ERROR: Data cleaning failed: ...
ERROR: Error processing column 'ABC': ...
ERROR: Invalid counts type: <class 'dict'>
```

---

## üìä Expected Output Format

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Output HTML ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á:

```html
<table>
  <thead>
    <tr>
      <th>Characteristic</th>
      <th>Total (N=100)</th>
      <th>Control (n=50)</th>
      <th>Treatment (n=50)</th>
      <th>OR (95% CI)</th>
      <th>SMD</th>
      <th>P-value</th>
      <th>Test</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Age (Years)</strong></td>
      <td>60.2 ¬± 10.1</td>
      <td>59.8 ¬± 9.8</td>
      <td>60.6 ¬± 10.4</td>
      <td>1.01 (0.98-1.04)</td>
      <td>0.078</td>
      <td><span class='p-not-significant'>0.543</span></td>
      <td>t-test</td>
    </tr>
    <tr>
      <td><strong>Sex</strong></td>
      <td>Female: 48 (48.0%)<br>Male: 52 (52.0%)</td>
      <td>Female: 25 (50.0%)<br>Male: 25 (50.0%)</td>
      <td>Female: 23 (46.0%)<br>Male: 27 (54.0%)</td>
      <td>1.17 (0.52-2.65)</td>
      <td>0.080</td>
      <td><span class='p-not-significant'>0.704</span></td>
      <td>Chi-square</td>
    </tr>
  </tbody>
</table>
```

---

## ‚úÖ Checklist ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö categorical variables (binary & multi-level)
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö continuous variables (normal & skewed)
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ missing values
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ outliers
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö edge cases (empty groups, all NA, non-existent columns)
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö logs ‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ERROR
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö HTML output ‡∏ß‡πà‡∏≤‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö download HTML file
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö matched data (‡∏à‡∏≤‡∏Å PSM)
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (>10,000 rows)

---

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

### ‡πÉ‡∏ô Shiny App:

```python
# 1. Load data (tab_data.py)
df.set(your_dataframe)
var_meta.set(your_metadata)

# 2. Generate Table 1 (tab_baseline_matching.py)
@reactive.Effect
@reactive.event(input.btn_gen_table1)
def _generate_table1():
    data, label = current_t1_data()
    
    if data is None:
        ui.notification_show("No data loaded", type="warning")
        return
    
    group_col = input.sel_group_col()
    if group_col == "None":
        group_col = None
    
    selected_vars = input.sel_t1_vars()
    
    try:
        html = table_one.generate_table(
            data,
            selected_vars,
            group_col,
            var_meta.get(),
            or_style=input.radio_or_style()
        )
        html_content.set(html)
        ui.notification_show("‚úÖ Table generated", type="message")
        
    except ValueError as e:
        # ‚úÖ User-friendly error
        ui.notification_show(f"Cannot generate table: {str(e)}", type="error")
        
    except Exception as e:
        # ‚úÖ Unexpected error
        logger.exception("Table generation failed")
        ui.notification_show("Unexpected error - check logs", type="error")
```

---

## üìù ‡∏™‡∏£‡∏∏‡∏õ

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß:
1. ‚úÖ `get_stats_categorical_str` ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Series ‡πÅ‡∏•‡∏∞ dict
2. ‚úÖ Validate data cleaning success
3. ‚úÖ Validate column existence
4. ‚úÖ Error handling ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ table ‡∏û‡∏±‡∏á
5. ‚úÖ Enhanced logging ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö debugging

### ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á:
- ‚ö†Ô∏è **Original data ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç** - cleaning ‡∏ó‡∏≥‡∏ö‡∏ô copy ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‚ö†Ô∏è **Missing data** ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å handle ‡πÇ‡∏î‡∏¢ `clean_numeric_vector()`
- ‚ö†Ô∏è **Outliers** ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å remove ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ `handle_outliers_flag=True`)

### ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:
- ‚úÖ Robust error handling
- ‚úÖ Better logging
- ‚úÖ Data integrity preserved
- ‚úÖ User-friendly error messages
- ‚úÖ Continues processing even if some columns fail