import keyword

import numpy as np
import pandas as pd
import patsy
import plotly.graph_objects as go
from lifelines import CoxPHFitter

from logger import get_logger
from utils.data_cleaning import prepare_data_for_analysis

logger = get_logger(__name__)


def fit_cox_rcs(
    df: pd.DataFrame,
    duration_col: str,
    event_col: str,
    rcs_var: str,
    adjust_cols: list[str],
    knots: int = 4,
    ref_value: float | None = None,
    var_meta: dict[str, dict] | None = None,
) -> tuple[go.Figure, pd.DataFrame, dict[str, object] | None]:
    """
    Perform Restricted Cubic Spline (RCS) analysis for Cox Proportional Hazards.
    Uses patsy's 'cr' (natural cubic spline) basis.
    Requires knots >= 3.
    """
    if isinstance(knots, bool):
        return go.Figure(), pd.DataFrame(), {"error": "knots must be an integer"}
    if isinstance(knots, (int, np.integer)):
        knots = int(knots)
    elif isinstance(knots, (float, np.floating)):
        if not float(knots).is_integer():
            return go.Figure(), pd.DataFrame(), {"error": "knots must be an integer"}
        knots = int(knots)
    else:
        return go.Figure(), pd.DataFrame(), {"error": "knots must be an integer"}

    if knots < 3:
        return go.Figure(), pd.DataFrame(), {"error": "knots must be >= 3 for RCS"}

    def quote_col(name: str) -> str:
        """
        Quote column names for Patsy formulas if they contain spaces/special chars.
        If it's already a valid identifier, return as is.
        Otherwise wrap in Q("...").
        """
        if not name.isidentifier() or keyword.iskeyword(name):
            return f"Q({name!r})"
        return name

    # Guard against overlaps/duplicates in adjust_cols
    adjust_cols = [
        c
        for c in dict.fromkeys(adjust_cols)
        if c not in {rcs_var, duration_col, event_col}
    ]

    # 1. Prepare Data
    req_cols = [duration_col, event_col, rcs_var] + adjust_cols
    # Ensure numeric
    numeric_cols = [duration_col, event_col, rcs_var]

    try:
        data, missing_info = prepare_data_for_analysis(
            df,
            required_cols=req_cols,
            numeric_cols=numeric_cols,
            var_meta=var_meta,
            handle_missing="complete-case",
        )
    except Exception as e:
        return go.Figure(), pd.DataFrame(), {"error": str(e)}

    if len(data) == 0:
        return go.Figure(), pd.DataFrame(), {"error": "No data after cleaning"}

    # 2. Build Formula
    # cr() in patsy stands for Natural Cubic Spline (similar to rcs in R)
    # We drop the intercept after building X because CoxPHFitter handles baseline hazard

    formula_rhs = f"cr({quote_col(rcs_var)}, df={knots})"
    if adjust_cols:
        formula_rhs += " + " + " + ".join(quote_col(c) for c in adjust_cols)

    try:
        # Build design matrix
        y, X = patsy.dmatrices(
            f"{quote_col(duration_col)} + {quote_col(event_col)} ~ {formula_rhs}",
            data,
            return_type="dataframe",
        )

        # Capture design_info immediately as pandas operations strip it
        design_info = X.design_info

        # NOTE: patsy returns an intercept column by default.
        # We must drop it for CoxPHFitter.
        # By allowing intercept in formula, categorical vars use reference coding (n-1),
        # avoiding proper collinearity issues like Male+Female=1.
        if "Intercept" in X.columns:
            X = X.drop(columns=["Intercept"])
            # Update design_info to reflect dropped intercept is tricky,
            # but we essentially just need it for prediction.
            logger.info("Dropped Intercept column.")

        # FIX: Drop the first spline column to avoid multicollinearity (columns sum to 1)
        # Find columns generated by cr()
        spline_cols = [c for c in X.columns if "cr(" in c]
        if spline_cols:
            col_to_drop = spline_cols[0]
            logger.info(
                "Dropping spline column '%s' to avoid multicollinearity.", col_to_drop
            )
            # design_info already captured
            X = X.drop(columns=[col_to_drop])
        else:
            col_to_drop = None
            # design_info already captured

        # Fit Model
        cph = CoxPHFitter()
        # Combine X and duration/event for fitting
        fit_data = pd.concat([X, data[[duration_col, event_col]]], axis=1)
        # Handle duplicate columns if any
        fit_data = fit_data.loc[:, ~fit_data.columns.duplicated()]

        cph.fit(fit_data, duration_col=duration_col, event_col=event_col)

        # 3. Prediction (HR Profile)
        # Reference value (default to median)
        if ref_value is None:
            ref_value = data[rcs_var].median()

        # Create range for rcs_var
        x_min, x_max = data[rcs_var].min(), data[rcs_var].max()
        # Add buffer
        padding = (x_max - x_min) * 0.05
        pred_x = np.linspace(x_min - padding, x_max + padding, 200)

        # Create prediction dataframe
        pred_df = pd.DataFrame({rcs_var: pred_x})

        # Set adjustment vars to their means/modes
        for col in adjust_cols:
            is_num = pd.api.types.is_numeric_dtype(data[col])
            is_bool = pd.api.types.is_bool_dtype(data[col])
            # is_cat = pd.api.types.is_categorical_dtype(data[col]) -> Deprecated
            is_cat = isinstance(data[col].dtype, pd.CategoricalDtype)
            if is_num and not is_bool and not is_cat:
                pred_df[col] = data[col].mean()
            else:
                # For categorical/boolean, use mode (most frequent) and preserve dtype
                mode_val = data[col].mode(dropna=True)[0]
                pred_df[col] = pd.Series(
                    [mode_val] * len(pred_df), dtype=data[col].dtype
                )

        # Transform pred_df using the SAME design info as the training data
        # This ensures the spline basis is identical
        pred_X = patsy.build_design_matrices(
            [design_info], pred_df, return_type="dataframe"
        )[0]

        # Calculate log hazard relative to reference
        # We need the reference row transformed as well
        ref_df = pred_df.iloc[[0]].copy()
        ref_df[rcs_var] = ref_value
        ref_X = patsy.build_design_matrices(
            [design_info], ref_df, return_type="dataframe"
        )[0]

        # FIX: Drop the same column from prediction matrices if we dropped it from training
        if col_to_drop and col_to_drop in pred_X.columns:
            pred_X = pred_X.drop(columns=[col_to_drop])
        if "Intercept" in pred_X.columns:
            pred_X = pred_X.drop(columns=["Intercept"])

        if col_to_drop and col_to_drop in ref_X.columns:
            ref_X = ref_X.drop(columns=[col_to_drop])
        if "Intercept" in ref_X.columns:
            ref_X = ref_X.drop(columns=["Intercept"])

        # Contrast: X_pred - X_ref
        contrast = pred_X.values - ref_X.values

        # Log HR = contrast * beta
        # Check dimensions
        if contrast.shape[1] != len(cph.params_):
            logger.error(
                "Shape mismatch: Contrast %d vs Params %d",
                contrast.shape[1],
                len(cph.params_),
            )
            return (
                go.Figure(),
                pd.DataFrame(),
                {
                    "error": f"Shape mismatch: contrast columns ({contrast.shape[1]}) != model params ({len(cph.params_)})"
                },
            )

        beta = cph.params_.values
        log_hr = contrast.dot(beta)

        # Variance of Log HR = contrast * Cov * contrast.T
        # We only need diagonals (variance of each point)
        cov_mat = cph.variance_matrix_.values
        var_log_hr = np.sum(contrast.dot(cov_mat) * contrast, axis=1)
        var_log_hr = np.maximum(var_log_hr, 0)
        se_log_hr = np.sqrt(var_log_hr)

        # Convert to HR and CI
        hr = np.exp(log_hr)
        ci_lower = np.exp(log_hr - 1.96 * se_log_hr)
        ci_upper = np.exp(log_hr + 1.96 * se_log_hr)

        # 4. Plotting
        fig = go.Figure()

        # Confidence Interval (Band)
        fig.add_trace(
            go.Scatter(
                x=np.concatenate([pred_x, pred_x[::-1]]),
                y=np.concatenate([ci_upper, ci_lower[::-1]]),
                fill="toself",
                fillcolor="rgba(0,100,80,0.2)",
                line=dict(color="rgba(255,255,255,0)"),
                hoverinfo="skip",
                name="95% CI",
            )
        )

        # Main HR Line
        fig.add_trace(
            go.Scatter(
                x=pred_x,
                y=hr,
                mode="lines",
                line=dict(color="rgb(0,100,80)", width=2),
                name="Hazard Ratio",
            )
        )

        x_min_padded = x_min - padding
        x_max_padded = x_max + padding

        # Reference Line
        fig.add_shape(
            type="line",
            x0=x_min_padded,
            y0=1,
            x1=x_max_padded,
            y1=1,
            line=dict(color="gray", dash="dash", width=1),
        )

        # Reference Point Marker
        fig.add_trace(
            go.Scatter(
                x=[ref_value],
                y=[1],
                mode="markers",
                marker=dict(color="red", size=8, symbol="diamond"),
                name=f"Reference ({ref_value:.2f})",
            )
        )

        # Density / Rug plot at the bottom (Optional but nice)
        # Use simple rug plot logic
        rug_data = data[rcs_var].sample(
            min(500, len(data)), random_state=42
        )  # Sample if too large
        fig.add_trace(
            go.Scatter(
                x=rug_data,
                y=[0.1] * len(rug_data),  # Place near bottom
                mode="markers",
                marker=dict(color="black", size=5, symbol="line-ns-open"),
                name="Observations",
                showlegend=False,
                yaxis="y2",
            )
        )

        # Layout
        fig.update_layout(
            title=f"Restricted Cubic Spline: {rcs_var} (Ref={ref_value:.2f})",
            xaxis_title=rcs_var,
            yaxis_title="Hazard Ratio (95% CI)",
            template="plotly_white",
            height=550,
            hovermode="x unified",
            yaxis2=dict(
                domain=[0, 0.1],  # Bottom 10% for rug
                showgrid=False,
                zeroline=False,
                showticklabels=False,
                overlaying="y",
                range=[0, 1],
            ),
            yaxis=dict(
                domain=[0.15, 1],  # Top 85% for main plot
            ),
        )

        # Stats table (AIC, p-value for non-linearity is complex to extract easily without nested models,
        # so we return model summary)
        stats_df = cph.summary[["coef", "exp(coef)", "p", "z"]].reset_index()
        stats_df.rename(columns={"p": "P-value", "exp(coef)": "HR"}, inplace=True)
        stats_df["Method"] = f"RCS (knots={knots})"

        return fig, stats_df, missing_info

    except Exception as e:
        logger.error("RCS Fit Error: %s", e, exc_info=True)
        return go.Figure(), pd.DataFrame(), {"error": str(e)}
